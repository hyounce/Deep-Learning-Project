{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUboEeI0CH0A"
   },
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bIAunzfaCNAH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import Generator\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.datasets import load_files\n",
    "from torch import manual_seed as torch_manual_seed\n",
    "import random\n",
    "from torch.cuda import max_memory_allocated, set_device, manual_seed_all\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CelebA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whpECRG_B2Nj"
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    " \n",
    "# Define transformations for the dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CelebA dataset -- run as little as possible\n",
    "train_dataset = CelebA(root='data', split='train', target_type='attr', download=False, transform=transform)\n",
    "val_dataset = CelebA(root='data', split='valid', target_type='attr', download=False, transform=transform)\n",
    "test_dataset = CelebA(root='data', split='test', target_type='attr', download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lfs1KoO4ZqTx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Move to device\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        y = (y == 1).float()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            current = (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss.item():>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    # Average loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    total_correct = 0\n",
    "    total_labels = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y = (y == 1).float()\n",
    "\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # Apply sigmoid and compute multi-label accuracy\n",
    "            pred_labels = torch.sigmoid(pred) > 0.5\n",
    "            correct = (pred_labels == y.bool()).sum().item()\n",
    "            total_correct += correct\n",
    "            total_labels += y.numel()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    accuracy = total_correct / total_labels\n",
    "    print(f\"Test Error: \\n Accuracy: {100*accuracy:.2f}%, Avg loss: {test_loss:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzsmVBKeZ4S7"
   },
   "source": [
    "# model 1 - efficientNet_B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "du4NtUUpZrSs",
    "outputId": "fb49439e-c569-44cc-80a4-60d84e839f30",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloaders = {'train' : train_dl, \"val\" : val_dl}\n",
    "dataset_sizes = {'train' : len(train_dl.dataset), \"val\" : len(val_dl.dataset)}\n",
    "\n",
    "#model itself\n",
    "model_conv = torchvision.models.efficientnet_b1(weights=torchvision.models.EfficientNet_B1_Weights.DEFAULT)\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.classifier[1].in_features\n",
    "model_conv.classifier[1] = nn.Linear(num_ftrs, 40)\n",
    "model_conv = model_conv.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXa_zoPWZs0W",
    "outputId": "23bd04a8-6701-401c-a430-572d8489a070",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.200400  [   64/162770]\n",
      "loss: 0.202975  [ 1344/162770]\n",
      "loss: 0.195064  [ 2624/162770]\n",
      "loss: 0.205841  [ 3904/162770]\n",
      "loss: 0.214517  [ 5184/162770]\n",
      "loss: 0.201734  [ 6464/162770]\n",
      "loss: 0.194128  [ 7744/162770]\n",
      "loss: 0.209708  [ 9024/162770]\n",
      "loss: 0.214482  [10304/162770]\n",
      "loss: 0.183043  [11584/162770]\n",
      "loss: 0.199749  [12864/162770]\n",
      "loss: 0.201965  [14144/162770]\n",
      "loss: 0.205093  [15424/162770]\n",
      "loss: 0.187492  [16704/162770]\n",
      "loss: 0.217952  [17984/162770]\n",
      "loss: 0.207203  [19264/162770]\n",
      "loss: 0.201325  [20544/162770]\n",
      "loss: 0.200443  [21824/162770]\n",
      "loss: 0.209946  [23104/162770]\n",
      "loss: 0.187947  [24384/162770]\n",
      "loss: 0.208104  [25664/162770]\n",
      "loss: 0.200787  [26944/162770]\n",
      "loss: 0.213014  [28224/162770]\n",
      "loss: 0.216259  [29504/162770]\n",
      "loss: 0.198329  [30784/162770]\n",
      "loss: 0.207416  [32064/162770]\n",
      "loss: 0.209578  [33344/162770]\n",
      "loss: 0.198900  [34624/162770]\n",
      "loss: 0.192838  [35904/162770]\n",
      "loss: 0.206435  [37184/162770]\n",
      "loss: 0.217654  [38464/162770]\n",
      "loss: 0.203293  [39744/162770]\n",
      "loss: 0.196531  [41024/162770]\n",
      "loss: 0.229398  [42304/162770]\n",
      "loss: 0.203974  [43584/162770]\n",
      "loss: 0.186397  [44864/162770]\n",
      "loss: 0.220939  [46144/162770]\n",
      "loss: 0.220857  [47424/162770]\n",
      "loss: 0.221282  [48704/162770]\n",
      "loss: 0.196564  [49984/162770]\n",
      "loss: 0.213622  [51264/162770]\n",
      "loss: 0.196340  [52544/162770]\n",
      "loss: 0.195847  [53824/162770]\n",
      "loss: 0.208907  [55104/162770]\n",
      "loss: 0.220988  [56384/162770]\n",
      "loss: 0.187689  [57664/162770]\n",
      "loss: 0.188009  [58944/162770]\n",
      "loss: 0.207073  [60224/162770]\n",
      "loss: 0.202281  [61504/162770]\n",
      "loss: 0.205732  [62784/162770]\n",
      "loss: 0.214944  [64064/162770]\n",
      "loss: 0.199987  [65344/162770]\n",
      "loss: 0.205669  [66624/162770]\n",
      "loss: 0.195406  [67904/162770]\n",
      "loss: 0.209696  [69184/162770]\n",
      "loss: 0.200301  [70464/162770]\n",
      "loss: 0.198389  [71744/162770]\n",
      "loss: 0.197879  [73024/162770]\n",
      "loss: 0.201041  [74304/162770]\n",
      "loss: 0.190562  [75584/162770]\n",
      "loss: 0.204186  [76864/162770]\n",
      "loss: 0.178677  [78144/162770]\n",
      "loss: 0.204362  [79424/162770]\n",
      "loss: 0.195594  [80704/162770]\n",
      "loss: 0.207491  [81984/162770]\n",
      "loss: 0.202218  [83264/162770]\n",
      "loss: 0.206234  [84544/162770]\n",
      "loss: 0.194320  [85824/162770]\n",
      "loss: 0.179040  [87104/162770]\n",
      "loss: 0.196642  [88384/162770]\n",
      "loss: 0.182252  [89664/162770]\n",
      "loss: 0.216320  [90944/162770]\n",
      "loss: 0.194307  [92224/162770]\n",
      "loss: 0.194856  [93504/162770]\n",
      "loss: 0.203585  [94784/162770]\n",
      "loss: 0.199448  [96064/162770]\n",
      "loss: 0.196392  [97344/162770]\n",
      "loss: 0.201620  [98624/162770]\n",
      "loss: 0.204257  [99904/162770]\n",
      "loss: 0.203272  [101184/162770]\n",
      "loss: 0.198656  [102464/162770]\n",
      "loss: 0.196123  [103744/162770]\n",
      "loss: 0.196024  [105024/162770]\n",
      "loss: 0.218257  [106304/162770]\n",
      "loss: 0.210667  [107584/162770]\n",
      "loss: 0.211865  [108864/162770]\n",
      "loss: 0.207559  [110144/162770]\n",
      "loss: 0.200353  [111424/162770]\n",
      "loss: 0.217704  [112704/162770]\n"
     ]
    }
   ],
   "source": [
    "#running model\n",
    "epochs = 1\n",
    "avg_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    model_conv.train()\n",
    "    LOSS = train_loop(train_dl, model_conv, criterion, optimizer_conv)\n",
    "    model_conv.eval()\n",
    "    test_loop(val_dl, model_conv, criterion)\n",
    "    avg_losses.append(LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "zlcvidmPO05g",
    "outputId": "e0b81794-bb6e-4e49-ebb7-e8fd22f8753a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the avg loss for model 1\n",
    "cpu_avg_losses = [loss.cpu().item() for loss in avg_losses]\n",
    "plt.plot(cpu_avg_losses)\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Average loss for Model 1 - efficientNet_b1\")\n",
    "plt.title(\"Avergae loss for Model 1 per epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
