{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0321c46-22db-443e-ad51-de10b7b30a27",
   "metadata": {},
   "source": [
    "## Helper Code to Load CelebA_resnet18.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de832f65-1bdf-4e15-a273-f01a12378ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CelebA\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b978a33-07be-4e14-a8ab-c84c2adfe76f",
   "metadata": {},
   "source": [
    "### Run this code to load the model from the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a11ad01-9f69-44f4-bedc-cea424f0b3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgp3aq/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/wgp3aq/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# define model architecture\n",
    "class MultiLabelResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLabelResNet, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=False)\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 40),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# instantiate\n",
    "model = MultiLabelResNet()\n",
    "\n",
    "# load WEIGHTS from saved model\n",
    "model.load_state_dict(torch.load(\"CelebA_resnet18.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()  # Set to evaluation mode \n",
    "\n",
    "print(\"model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c3166-8d52-46c7-90fe-0ec7f1b1bda9",
   "metadata": {},
   "source": [
    "### The code below runs the test data on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537503f-d51b-4cd5-8bed-abdd2dcbe966",
   "metadata": {},
   "source": [
    "**This is just to confirm it is loaded correctly and runs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92207430-929d-4236-9b4f-7553ed031b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found or corrupted. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m)), \n\u001b[1;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(), \n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# load the CelebA dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m######### SET download=True if you have never downloaded the data this way before. Each time after that set download=False ##########\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCelebA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m CelebA(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, target_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattr\u001b[39m\u001b[38;5;124m'\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     11\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CelebA(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, target_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattr\u001b[39m\u001b[38;5;124m'\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torchvision/datasets/celeba.py:88\u001b[0m, in \u001b[0;36mCelebA.__init__\u001b[0;34m(self, root, split, target_type, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m split_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     95\u001b[0m }\n\u001b[1;32m     96\u001b[0m split_ \u001b[38;5;241m=\u001b[39m split_map[verify_str_arg(split\u001b[38;5;241m.\u001b[39mlower(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m))]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found or corrupted. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "# define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)), \n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "# load the CelebA dataset\n",
    "######### SET download=True if you have never downloaded the data this way before. Each time after that set download=False ##########\n",
    "train_dataset = CelebA(root='data', split='train', target_type='attr', download=True, transform=transform)\n",
    "val_dataset = CelebA(root='data', split='valid', target_type='attr', download=True, transform=transform)\n",
    "test_dataset = CelebA(root='data', split='test', target_type='attr', download=True, transform=transform)\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566940e-9e86-41d6-82f4-24849c464b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images \n",
    "        labels = labels.float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        outputs = outputs \n",
    "\n",
    "        all_outputs.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "all_outputs = torch.cat(all_outputs).cpu()\n",
    "all_labels = torch.cat(all_labels).cpu()\n",
    "\n",
    "preds = (all_outputs >= 0.5).float()\n",
    "\n",
    "mean_accuracy = (preds == all_labels).float().mean().item()\n",
    "print(f\"test set mean accuracy: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7152861-9570-4d58-b723-1f91dc1a6c99",
   "metadata": {},
   "source": [
    "**If the above output is 0.8988 the model should be ready to go**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a8b13-9f8f-4c54-8851-a661d970ec92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21304494-f495-4bee-8777-c4b9d9acbf77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a556f-6f85-4b2c-9032-3cb3b9b0eff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212af1e9-f29f-41cf-9bc5-0eeda3b2a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
